{
  "vocab_size": 30000,
  "hidden_size": 256,
  "num_hidden_layers": 4,
  "num_attention_heads": 4,
  "intermediate_size": 1024,
  "max_position_embeddings": 512,
  "type_vocab_size": 2,
  "hidden_dropout_prob": 0.1,
  "attention_probs_dropout_prob": 0.1,
  "batch_size": 32,
  "learning_rate": 1e-4,
  "weight_decay": 0.01,
  "adam_eps": 1e-6,
  "num_train_steps": 20000,
  "warmup_steps": 1000,
  "max_seq_length": 128,
  "mask_prob": 0.15,
  "nsp_prob": 0.5,
  "save_every": 2000,
  "device": "cuda"
}
